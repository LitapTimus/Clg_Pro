{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdccd819",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "93cba3ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'sample_excel.xlsx'\n",
    "df=pd.read_excel(file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "74722b7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>roll_no.</th>\n",
       "      <th>year</th>\n",
       "      <th>th</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2024</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2024</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2024</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2024</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2024</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   roll_no.  year  th\n",
       "0         1  2024  57\n",
       "1         2  2024  70\n",
       "2         3  2024  59\n",
       "3         4  2024  61\n",
       "4         5  2024  65"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f81fa775",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Worksheet named 'Endsem_res_3y' not found",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Assuming 'sample_excel.xlsx' has columns: 'year', 'roll_no.', 'th'\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m df_Endsem_res = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_excel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msheet_name\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mEndsem_res_3y\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      4\u001b[39m max_marks_dict = {\n\u001b[32m      5\u001b[39m     \u001b[32m2022\u001b[39m: \u001b[32m80\u001b[39m,\n\u001b[32m      6\u001b[39m     \u001b[32m2023\u001b[39m: \u001b[32m80\u001b[39m,\n\u001b[32m      7\u001b[39m     \u001b[32m2024\u001b[39m: \u001b[32m80\u001b[39m\n\u001b[32m      8\u001b[39m }\n\u001b[32m     10\u001b[39m \u001b[38;5;66;03m# --- Calculations for Yearly Data ---\u001b[39;00m\n\u001b[32m     11\u001b[39m \n\u001b[32m     12\u001b[39m \u001b[38;5;66;03m# Create the main summary DataFrame\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Sumit Patil\\Desktop\\Projects\\Clg_project\\xie_venv\\Lib\\site-packages\\pandas\\io\\excel\\_base.py:508\u001b[39m, in \u001b[36mread_excel\u001b[39m\u001b[34m(io, sheet_name, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, date_format, thousands, decimal, comment, skipfooter, storage_options, dtype_backend, engine_kwargs)\u001b[39m\n\u001b[32m    502\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    503\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mEngine should not be specified when passing \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    504\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33man ExcelFile - ExcelFile already has the engine set\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    505\u001b[39m     )\n\u001b[32m    507\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m508\u001b[39m     data = \u001b[43mio\u001b[49m\u001b[43m.\u001b[49m\u001b[43mparse\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    509\u001b[39m \u001b[43m        \u001b[49m\u001b[43msheet_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43msheet_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    510\u001b[39m \u001b[43m        \u001b[49m\u001b[43mheader\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    511\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnames\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnames\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    512\u001b[39m \u001b[43m        \u001b[49m\u001b[43mindex_col\u001b[49m\u001b[43m=\u001b[49m\u001b[43mindex_col\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    513\u001b[39m \u001b[43m        \u001b[49m\u001b[43musecols\u001b[49m\u001b[43m=\u001b[49m\u001b[43musecols\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    514\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    515\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconverters\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconverters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    516\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrue_values\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrue_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    517\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfalse_values\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfalse_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    518\u001b[39m \u001b[43m        \u001b[49m\u001b[43mskiprows\u001b[49m\u001b[43m=\u001b[49m\u001b[43mskiprows\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    519\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    520\u001b[39m \u001b[43m        \u001b[49m\u001b[43mna_values\u001b[49m\u001b[43m=\u001b[49m\u001b[43mna_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    521\u001b[39m \u001b[43m        \u001b[49m\u001b[43mkeep_default_na\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkeep_default_na\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    522\u001b[39m \u001b[43m        \u001b[49m\u001b[43mna_filter\u001b[49m\u001b[43m=\u001b[49m\u001b[43mna_filter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    523\u001b[39m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    524\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparse_dates\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparse_dates\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    525\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdate_parser\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdate_parser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    526\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdate_format\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdate_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    527\u001b[39m \u001b[43m        \u001b[49m\u001b[43mthousands\u001b[49m\u001b[43m=\u001b[49m\u001b[43mthousands\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    528\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdecimal\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecimal\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    529\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcomment\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcomment\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    530\u001b[39m \u001b[43m        \u001b[49m\u001b[43mskipfooter\u001b[49m\u001b[43m=\u001b[49m\u001b[43mskipfooter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    531\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdtype_backend\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype_backend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    532\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    533\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    534\u001b[39m     \u001b[38;5;66;03m# make sure to close opened file handles\u001b[39;00m\n\u001b[32m    535\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m should_close:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Sumit Patil\\Desktop\\Projects\\Clg_project\\xie_venv\\Lib\\site-packages\\pandas\\io\\excel\\_base.py:1616\u001b[39m, in \u001b[36mExcelFile.parse\u001b[39m\u001b[34m(self, sheet_name, header, names, index_col, usecols, converters, true_values, false_values, skiprows, nrows, na_values, parse_dates, date_parser, date_format, thousands, comment, skipfooter, dtype_backend, **kwds)\u001b[39m\n\u001b[32m   1576\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mparse\u001b[39m(\n\u001b[32m   1577\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1578\u001b[39m     sheet_name: \u001b[38;5;28mstr\u001b[39m | \u001b[38;5;28mint\u001b[39m | \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mint\u001b[39m] | \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mstr\u001b[39m] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[32m0\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1596\u001b[39m     **kwds,\n\u001b[32m   1597\u001b[39m ) -> DataFrame | \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, DataFrame] | \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mint\u001b[39m, DataFrame]:\n\u001b[32m   1598\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1599\u001b[39m \u001b[33;03m    Parse specified sheet(s) into a DataFrame.\u001b[39;00m\n\u001b[32m   1600\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   1614\u001b[39m \u001b[33;03m    >>> file.parse()  # doctest: +SKIP\u001b[39;00m\n\u001b[32m   1615\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1616\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_reader\u001b[49m\u001b[43m.\u001b[49m\u001b[43mparse\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1617\u001b[39m \u001b[43m        \u001b[49m\u001b[43msheet_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43msheet_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1618\u001b[39m \u001b[43m        \u001b[49m\u001b[43mheader\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1619\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnames\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnames\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1620\u001b[39m \u001b[43m        \u001b[49m\u001b[43mindex_col\u001b[49m\u001b[43m=\u001b[49m\u001b[43mindex_col\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1621\u001b[39m \u001b[43m        \u001b[49m\u001b[43musecols\u001b[49m\u001b[43m=\u001b[49m\u001b[43musecols\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1622\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconverters\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconverters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1623\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrue_values\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrue_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1624\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfalse_values\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfalse_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1625\u001b[39m \u001b[43m        \u001b[49m\u001b[43mskiprows\u001b[49m\u001b[43m=\u001b[49m\u001b[43mskiprows\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1626\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1627\u001b[39m \u001b[43m        \u001b[49m\u001b[43mna_values\u001b[49m\u001b[43m=\u001b[49m\u001b[43mna_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1628\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparse_dates\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparse_dates\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1629\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdate_parser\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdate_parser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1630\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdate_format\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdate_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1631\u001b[39m \u001b[43m        \u001b[49m\u001b[43mthousands\u001b[49m\u001b[43m=\u001b[49m\u001b[43mthousands\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1632\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcomment\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcomment\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1633\u001b[39m \u001b[43m        \u001b[49m\u001b[43mskipfooter\u001b[49m\u001b[43m=\u001b[49m\u001b[43mskipfooter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1634\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdtype_backend\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype_backend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1635\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1636\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Sumit Patil\\Desktop\\Projects\\Clg_project\\xie_venv\\Lib\\site-packages\\pandas\\io\\excel\\_base.py:773\u001b[39m, in \u001b[36mBaseExcelReader.parse\u001b[39m\u001b[34m(self, sheet_name, header, names, index_col, usecols, dtype, true_values, false_values, skiprows, nrows, na_values, verbose, parse_dates, date_parser, date_format, thousands, decimal, comment, skipfooter, dtype_backend, **kwds)\u001b[39m\n\u001b[32m    770\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mReading sheet \u001b[39m\u001b[38;5;132;01m{\u001b[39;00masheetname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    772\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(asheetname, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m773\u001b[39m     sheet = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_sheet_by_name\u001b[49m\u001b[43m(\u001b[49m\u001b[43masheetname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# assume an integer if not a string\u001b[39;00m\n\u001b[32m    775\u001b[39m     sheet = \u001b[38;5;28mself\u001b[39m.get_sheet_by_index(asheetname)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Sumit Patil\\Desktop\\Projects\\Clg_project\\xie_venv\\Lib\\site-packages\\pandas\\io\\excel\\_openpyxl.py:582\u001b[39m, in \u001b[36mOpenpyxlReader.get_sheet_by_name\u001b[39m\u001b[34m(self, name)\u001b[39m\n\u001b[32m    581\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget_sheet_by_name\u001b[39m(\u001b[38;5;28mself\u001b[39m, name: \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m582\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mraise_if_bad_sheet_by_name\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    583\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.book[name]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Sumit Patil\\Desktop\\Projects\\Clg_project\\xie_venv\\Lib\\site-packages\\pandas\\io\\excel\\_base.py:624\u001b[39m, in \u001b[36mBaseExcelReader.raise_if_bad_sheet_by_name\u001b[39m\u001b[34m(self, name)\u001b[39m\n\u001b[32m    622\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mraise_if_bad_sheet_by_name\u001b[39m(\u001b[38;5;28mself\u001b[39m, name: \u001b[38;5;28mstr\u001b[39m) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    623\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.sheet_names:\n\u001b[32m--> \u001b[39m\u001b[32m624\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mWorksheet named \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m not found\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mValueError\u001b[39m: Worksheet named 'Endsem_res_3y' not found"
     ]
    }
   ],
   "source": [
    "# Assuming 'sample_excel.xlsx' has columns: 'year', 'roll_no.', 'th'\n",
    "df_Endsem_res = pd.read_excel(file_path, sheet_name=\"Endsem_res_3y\")\n",
    "\n",
    "max_marks_dict = {\n",
    "    2022: 80,\n",
    "    2023: 80,\n",
    "    2024: 80\n",
    "}\n",
    "\n",
    "# --- Calculations for Yearly Data ---\n",
    "\n",
    "# Create the main summary DataFrame\n",
    "summary = df_Endsem_res.groupby(\"year\").agg(\n",
    "    total_students=(\"roll_no.\", \"nunique\"),\n",
    "    th_total=(\"th\", \"sum\")\n",
    ")\n",
    "\n",
    "summary[\"max_marks\"] = summary.index.map(max_marks_dict)\n",
    "\n",
    "# Calculate class average marks for each year\n",
    "summary[\"class_avg_marks\"] = summary[\"th_total\"] / summary[\"total_students\"]\n",
    "summary[\"%_class_avg_marks\"] =((summary[\"class_avg_marks\"] / summary[\"max_marks\"]) * 100)\n",
    "\n",
    "# Calculate Students Who Achieved the Average\n",
    "df_merged = pd.merge(df_Endsem_res, summary[['class_avg_marks']], on='year', how='left')\n",
    "achieved_avg_count = df_merged[df_merged['th'] >= df_merged['class_avg_marks']].groupby('year').size()\n",
    "summary['students_achieved_avg'] = achieved_avg_count\n",
    "summary['%_students_achieved_avg'] = np.round(\n",
    "    (summary['students_achieved_avg'] / summary['total_students']) * 100,\n",
    "    2\n",
    ")\n",
    "\n",
    "# Continue with the other calculations\n",
    "# Calculate Attainment Percentage\n",
    "summary[\"attainment_%\"] = np.ceil(\n",
    "    (summary[\"th_total\"] * 100) / (summary[\"total_students\"] * summary[\"max_marks\"])\n",
    ")\n",
    "# This column is for the scaled value, initialized with empty values\n",
    "summary['attainment_scaled_3'] = np.nan\n",
    "\n",
    "\n",
    "# --- NEW: Calculate and Add Overall Averages for ALL Columns ---\n",
    "\n",
    "# 1. Calculate the mean of every column from the yearly data\n",
    "overall_averages = summary.mean()\n",
    "\n",
    "# 2. The scaled attainment is not a simple mean, so calculate it separately\n",
    "#    based on the average of the 'attainment_%' column\n",
    "avg_attainment_scaled = round((overall_averages['attainment_%'] * 3) / 100, 2)\n",
    "# 3. Add the 'Overall Average' row using the calculated means\n",
    "summary.loc['Overall Average'] = overall_averages\n",
    "\n",
    "# 4. Place the specially calculated scaled value into the correct cell\n",
    "summary.loc['Overall Average', 'attainment_scaled_3'] = avg_attainment_scaled\n",
    "\n",
    "\n",
    "# --- Display and Export the Final DataFrame ---\n",
    "\n",
    "print(\"--- Final Combined Summary DataFrame ---\")\n",
    "# Reordering columns for better readability\n",
    "summary = summary[[\n",
    "    'total_students', \n",
    "    'th_total', \n",
    "    'class_avg_marks', \n",
    "    '%_class_avg_marks', \n",
    "    'students_achieved_avg', \n",
    "    '%_students_achieved_avg', \n",
    "    'max_marks', \n",
    "    'attainment_%', \n",
    "    'attainment_scaled_3'\n",
    "]]\n",
    "\n",
    "# Rounding off numerical values for better presentation\n",
    "summary = summary.round(2)\n",
    "\n",
    "# Display the final table\n",
    "summary\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc3d1c6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   level  % of the student  % of marks\n",
      "0      1                44          58\n",
      "1      2                49          58\n",
      "2      3                54          58\n"
     ]
    }
   ],
   "source": [
    "#sheet 2 Goal set\n",
    "stud_per_achieved_avg=math.ceil((summary['%_students_achieved_avg']['Overall Average']))\n",
    "class_per_avg_marks=math.ceil((summary['%_class_avg_marks']['Overall Average']))\n",
    "data = {\n",
    "    \"level\":[1,2,3],\n",
    "    \"% of the student\": [stud_per_achieved_avg-5,stud_per_achieved_avg,stud_per_achieved_avg+5],\n",
    "    \"% of marks\": [class_per_avg_marks,class_per_avg_marks,class_per_avg_marks]\n",
    "}\n",
    "\n",
    "goalset = pd.DataFrame(data)\n",
    "print(goalset)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faf05eb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- VALIDATION & DEBUG LOG ---\n",
      "\n",
      "Processing CO: 2343113.1\n",
      " Mapping: IAT1 ‚Üí CO1_tool_1\n",
      " Mapping: MCQ ‚Üí CO1_tool_2\n",
      " Mapping: Assignment ‚Üí CO1_tool_3\n",
      "\n",
      "Processing CO: 2343113.2\n",
      " Mapping: IAT1 ‚Üí CO2_tool_1\n",
      " Mapping: MCQ ‚Üí CO2_tool_2\n",
      " Mapping: Mind Mapping ‚Üí CO2_tool_3\n",
      "\n",
      "Processing CO: 2343113.3\n",
      " Mapping: IAT1 ‚Üí CO3_tool_1\n",
      " Mapping: MCQ ‚Üí CO3_tool_2\n",
      " Mapping: Assignment ‚Üí CO3_tool_3\n",
      "\n",
      "Processing CO: 2343113.4\n",
      " Mapping: IAT2 ‚Üí CO4_tool_1\n",
      " Mapping: MCQ ‚Üí CO4_tool_2\n",
      " Mapping: Assignment ‚Üí CO4_tool_3\n",
      "\n",
      "Processing CO: 2343113.5\n",
      " Mapping: IAT2 ‚Üí CO5_tool_1\n",
      " Mapping: MCQ ‚Üí CO5_tool_2\n",
      " Mapping: Assignment ‚Üí CO5_tool_3\n",
      "\n",
      "Processing CO: 2343113.6\n",
      " Mapping: IAT2 ‚Üí CO6_tool_1\n",
      " Mapping: MCQ ‚Üí CO6_tool_2\n",
      " Mapping: Assignment ‚Üí CO6_tool_3\n",
      "\n",
      "--- PROCESS COMPLETED ---\n",
      "                                       CO Statements  Tool 1 Total  Tool 1 %  \\\n",
      "0  Students will be able to discuss the need of a...            36     50.00   \n",
      "1  Students will be able to analyze and design co...            59     81.94   \n",
      "2  Students will be able to construct relational ...            26     36.11   \n",
      "3  Students will be able to construct query using...            21     29.17   \n",
      "4  Students will be able to apply the concept of ...            33     45.83   \n",
      "5  Students will be able to explain the concept o...            58     80.56   \n",
      "\n",
      "   Tool 2 Total  Tool 2 %  Tool 3 Total  Tool 3 %  \\\n",
      "0            54     75.00            70     97.22   \n",
      "1            59     81.94            72    100.00   \n",
      "2            62     86.11            70     97.22   \n",
      "3            57     79.17            70     97.22   \n",
      "4            52     72.22            70     97.22   \n",
      "5            61     84.72            70     97.22   \n",
      "\n",
      "   % considering best 2 tools avg  \n",
      "0                           86.11  \n",
      "1                           90.97  \n",
      "2                           91.66  \n",
      "3                           88.20  \n",
      "4                           84.72  \n",
      "5                           90.97  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "def calculate_attainment_summary(file_path):\n",
    "\n",
    "    # ============================\n",
    "    # 1. LOAD MARKS SHEET\n",
    "    # ============================\n",
    "    df = pd.read_excel(file_path, sheet_name=\"IAT+tools\")\n",
    "\n",
    "    # Extract Max Marks row\n",
    "    max_marks_row = df[df['Roll_no.'] == 'Max_Marks']\n",
    "    if max_marks_row.empty:\n",
    "        raise ValueError(\"'Max_Marks' row is missing in 'IAT+tools' sheet.\")\n",
    "\n",
    "    max_marks = max_marks_row.iloc[0].to_dict()\n",
    "    max_marks.pop(\"Roll_no.\")\n",
    "\n",
    "    # Remove Max Marks Row\n",
    "    df = df[df['Roll_no.'] != 'Max_Marks']\n",
    "    total_students = len(df)\n",
    "\n",
    "    # Convert marks safely\n",
    "    for col in max_marks:\n",
    "        df[col] = pd.to_numeric(df[col], errors=\"coerce\")\n",
    "\n",
    "    # ============================\n",
    "    # 2. LOAD TOOL ASSIGNMENT\n",
    "    # ============================\n",
    "    tools_df = pd.read_excel(file_path, sheet_name=\"Tool Assignment\")\n",
    "\n",
    "    THRESHOLD = class_per_avg_marks\n",
    "    output = []\n",
    "\n",
    "    print(\"\\n--- VALIDATION & DEBUG LOG ---\")\n",
    "\n",
    "    # ============================\n",
    "    # 3. PROCESS EACH CO\n",
    "    # ============================\n",
    "    for index, row in tools_df.iterrows():\n",
    "\n",
    "        co_id = row.get(\"CO-ID\")\n",
    "        co_statement = row.get(\"CO Statement\")\n",
    "\n",
    "        print(f\"\\nProcessing CO: {co_id}\")\n",
    "\n",
    "        # Read tools\n",
    "        t1 = row.get(\"Tool1\")\n",
    "        t2 = row.get(\"Tool2\")\n",
    "        t3 = row.get(\"Tool3\")\n",
    "\n",
    "        # ============================\n",
    "        # VALIDATION 1 ‚Äî TOOL ORDER\n",
    "        # ============================\n",
    "        if pd.isna(t1) and (not pd.isna(t2) or not pd.isna(t3)):\n",
    "            print(\"‚ùå ERROR: Tool1 is empty but Tool2/Tool3 is filled.\")\n",
    "            print(\"üëâ Fix Excel: Always fill Tool1 first.\")\n",
    "            continue\n",
    "\n",
    "        if pd.isna(t2) and not pd.isna(t3):\n",
    "            print(\"‚ùå ERROR: Tool2 is empty but Tool3 is filled.\")\n",
    "            print(\"üëâ Fix Excel: Do not skip Tool2.\")\n",
    "            continue\n",
    "\n",
    "        # ============================\n",
    "        # VALIDATION 2 ‚Äî MINIMUM TOOLS\n",
    "        # ============================\n",
    "        tools = [t for t in [t1, t2, t3] if not pd.isna(t)]\n",
    "\n",
    "        if len(tools) < 2:\n",
    "            print(\"‚ùå ERROR: Less than 2 tools provided.\")\n",
    "            print(\"üëâ At least TWO tools are required per CO.\")\n",
    "            continue\n",
    "\n",
    "        # Extract CO number from ID\n",
    "        try:\n",
    "            co_number = int(str(co_id).split(\".\")[-1])\n",
    "        except:\n",
    "            print(\"‚ùå ERROR: CO-ID format invalid.\")\n",
    "            print(\"üëâ Expected: format like '2343113.1' or 'CO1'\")\n",
    "            continue\n",
    "\n",
    "        tool_results = []\n",
    "\n",
    "        # ============================\n",
    "        # 4. CALCULATION PER SLOT\n",
    "        # ============================\n",
    "        for slot_index, tool_name in enumerate(tools, start=1):\n",
    "\n",
    "            column_name = f\"CO{co_number}_tool_{slot_index}\"\n",
    "\n",
    "            print(f\" Mapping: {tool_name} ‚Üí {column_name}\")\n",
    "\n",
    "            # ============================\n",
    "            # VALIDATION 3 ‚Äî COLUMN EXISTS\n",
    "            # ============================\n",
    "            if column_name not in df.columns:\n",
    "                print(f\"‚ùå ERROR: Column '{column_name}' NOT FOUND in marks sheet.\")\n",
    "                print(\"üëâ Check column names in 'IAT+tools' sheet.\")\n",
    "                continue\n",
    "\n",
    "            max_mark = max_marks.get(column_name)\n",
    "\n",
    "            # ============================\n",
    "            # VALIDATION 4 ‚Äî MAX MARKS VALID\n",
    "            # ============================\n",
    "            if pd.isna(max_mark) or max_mark == 0:\n",
    "                print(f\"‚ùå ERROR: Invalid max mark for {column_name}.\")\n",
    "                print(\"üëâ Fix 'Max_Marks' row.\")\n",
    "                continue\n",
    "\n",
    "            # ============================\n",
    "            # CALCULATION\n",
    "            # ============================\n",
    "            percent_scores = (df[column_name] / max_mark) * 100\n",
    "            achieved = (percent_scores >= THRESHOLD).sum()\n",
    "            percent = (achieved / total_students) * 100\n",
    "\n",
    "            tool_results.append({\n",
    "                \"tool\": tool_name,\n",
    "                \"students\": achieved,\n",
    "                \"percent\": round(percent, 2)\n",
    "            })\n",
    "\n",
    "        # ============================\n",
    "        # VALIDATION 5 ‚Äî BEST TWO SAFETY\n",
    "        # ============================\n",
    "        if len(tool_results) < 2:\n",
    "            print(\"‚ùå ERROR: Less than 2 valid tools after validation.\")\n",
    "            print(\"üëâ Check marks sheet & mapping.\")\n",
    "            continue\n",
    "\n",
    "        # ============================\n",
    "        # 5. SELECT BEST TWO\n",
    "        # ============================\n",
    "        best_two = sorted(tool_results, key=lambda x: x['percent'], reverse=True)[:2]\n",
    "        best_avg = round(\n",
    "            (best_two[0]['percent'] + best_two[1]['percent']) / 2,\n",
    "            2\n",
    "        )\n",
    "\n",
    "        # ============================\n",
    "        # 6. OUTPUT FORMAT\n",
    "        # ============================\n",
    "        row_out = {\"CO Statements\": co_statement}\n",
    "\n",
    "        for i, tr in enumerate(tool_results):\n",
    "            row_out[f\"Tool {i+1} Total\"] = tr[\"students\"]\n",
    "            row_out[f\"Tool {i+1} %\"] = tr[\"percent\"]\n",
    "\n",
    "        row_out[\"% considering best 2 tools avg\"] = best_avg\n",
    "        output.append(row_out)\n",
    "\n",
    "    # ============================\n",
    "    # FINAL TABLE\n",
    "    # ============================\n",
    "    print(\"\\n--- PROCESS COMPLETED ---\")\n",
    "    return pd.DataFrame(output)\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    direct_attainment_df= calculate_attainment_summary(file_path)\n",
    "    print(direct_attainment_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1d7fd6a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'file_path' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# -----------------------------------\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# LOAD DATA\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m# -----------------------------------\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m raw = pd.read_excel(\u001b[43mfile_path\u001b[49m, sheet_name=\u001b[33m'\u001b[39m\u001b[33mESE\u001b[39m\u001b[33m'\u001b[39m, header=\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m      9\u001b[39m \u001b[38;5;66;03m# -----------------------------------\u001b[39;00m\n\u001b[32m     10\u001b[39m \u001b[38;5;66;03m# EXTRACT HEADERS\u001b[39;00m\n\u001b[32m     11\u001b[39m \u001b[38;5;66;03m# -----------------------------------\u001b[39;00m\n\u001b[32m     12\u001b[39m questions = raw.iloc[\u001b[32m0\u001b[39m].ffill()\n",
      "\u001b[31mNameError\u001b[39m: name 'file_path' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "# -----------------------------------\n",
    "# LOAD DATA\n",
    "# -----------------------------------\n",
    "raw = pd.read_excel(file_path, sheet_name='ESE', header=None)\n",
    "\n",
    "# -----------------------------------\n",
    "# EXTRACT HEADERS\n",
    "# -----------------------------------\n",
    "questions = raw.iloc[0].ffill()\n",
    "co_map = raw.iloc[1]\n",
    "max_marks = raw.iloc[2]\n",
    "\n",
    "# -----------------------------------\n",
    "# FIND FIRST STUDENT ROW\n",
    "# -----------------------------------\n",
    "first_student_row = raw[\n",
    "    raw.iloc[:, 0].apply(lambda x: str(x).strip().isdigit())\n",
    "].index[0]\n",
    "\n",
    "marks_df = raw.iloc[first_student_row:].reset_index(drop=True)\n",
    "\n",
    "# First column = Roll No\n",
    "roll_col = marks_df.iloc[:, 0]\n",
    "marks_only = marks_df.iloc[:, 1:]\n",
    "\n",
    "# Convert max marks to numeric\n",
    "max_marks = pd.to_numeric(max_marks[1:], errors=\"coerce\")\n",
    "\n",
    "# Fix merged headers\n",
    "questions = questions[1:].ffill()\n",
    "co_map = co_map[1:]\n",
    "\n",
    "# -----------------------------------\n",
    "# PROCESS QUESTION-WISE\n",
    "# -----------------------------------\n",
    "results = []\n",
    "\n",
    "for idx, col in enumerate(marks_only.columns):\n",
    "\n",
    "    question = questions.iloc[idx]\n",
    "    coa = co_map.iloc[idx]\n",
    "    full_marks = max_marks.iloc[idx]\n",
    "\n",
    "    # -----------------------------------\n",
    "    # CLEANING LOGIC (IMPORTANT FIX)\n",
    "    # -----------------------------------\n",
    "    scores = marks_only[col]\n",
    "\n",
    "    # Remove whitespace / empty cells\n",
    "    scores = scores.replace(r'^\\s*$', np.nan, regex=True)\n",
    "\n",
    "    # Convert safely to numeric\n",
    "    scores = pd.to_numeric(scores, errors=\"coerce\")\n",
    "\n",
    "    # Drop missing values\n",
    "    scores = scores.dropna()\n",
    "\n",
    "    # OPTIONAL: Remove zeros if zero = not attempted\n",
    "    # scores = scores[scores > 0]\n",
    "\n",
    "    if len(scores) == 0:\n",
    "        continue\n",
    "\n",
    "    # -----------------------------------\n",
    "    # METRICS (FIXED)\n",
    "    # -----------------------------------\n",
    "    attempted = scores.count()\n",
    "\n",
    "    class_avg = scores.mean()\n",
    "    class_avg_percent = (class_avg / full_marks) * 100\n",
    "\n",
    "    above_threshold = ((scores / full_marks) * 100 >= class_per_avg_marks).sum()\n",
    "    percent_above = (above_threshold / attempted) * 100\n",
    "\n",
    "    # -----------------------------------\n",
    "    # STORE\n",
    "    # -----------------------------------\n",
    "    results.append({\n",
    "        \"Question\": question,\n",
    "        \"CO\": coa,\n",
    "        \"Max Marks\": full_marks,\n",
    "        \"No. of Students Attempted\": attempted,\n",
    "        \"No. >= Threshold\": above_threshold,\n",
    "        \"% >= Threshold\": round(percent_above, 2),\n",
    "        \"% Class Avg Marks\": round(class_avg_percent, 2)\n",
    "    })\n",
    "\n",
    "# -----------------------------------\n",
    "# FINAL DATAFRAME\n",
    "# -----------------------------------\n",
    "final_df = pd.DataFrame(results)\n",
    "\n",
    "# SHOW RESULT\n",
    "final_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2db25e13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of students: 72\n",
      "     3's (num)    3's (%)  2's (num)    2's (%)  1's (num)   1's (%)  \\\n",
      "CO1       44.0  61.111111       28.0  38.888889        0.0  0.000000   \n",
      "CO2       37.0  51.388889       35.0  48.611111        0.0  0.000000   \n",
      "CO3       38.0  52.777778       34.0  47.222222        0.0  0.000000   \n",
      "CO4       40.0  55.555556       31.0  43.055556        1.0  1.388889   \n",
      "CO5       38.0  52.777778       34.0  47.222222        0.0  0.000000   \n",
      "CO6       39.0  54.166667       32.0  44.444444        1.0  1.388889   \n",
      "\n",
      "     Overall Average %  \n",
      "CO1              87.04  \n",
      "CO2              83.80  \n",
      "CO3              84.26  \n",
      "CO4              84.72  \n",
      "CO5              84.26  \n",
      "CO6              84.26  \n"
     ]
    }
   ],
   "source": [
    "CES_df = pd.read_excel(\"sample_excel.xlsx\",sheet_name=\"CES\")\n",
    "\n",
    "# Step 1: Number of students\n",
    "student_num = CES_df[\"Sr. No\"].nunique()\n",
    "print(\"Number of students:\", student_num)\n",
    "\n",
    "# Step 2: Create dictionary to hold results\n",
    "results = {}\n",
    "\n",
    "# Step 3: Loop through CO1 to CO6\n",
    "for co in [c for c in CES_df.columns if c.startswith(\"CO\")]:\n",
    "    counts = CES_df[co].value_counts()\n",
    "\n",
    "    # Raw numbers\n",
    "    num_3 = counts.get(3, 0)\n",
    "    num_2 = counts.get(2, 0)\n",
    "    num_1 = counts.get(1, 0)\n",
    "\n",
    "    # Percentages\n",
    "    perc_3 = (num_3 * 100) / student_num\n",
    "    perc_2 = (num_2 * 100) / student_num\n",
    "    perc_1 = (num_1 * 100) / student_num\n",
    "\n",
    "    results[co] = {\n",
    "        \"3's (num)\": num_3, \"3's (%)\": perc_3,\n",
    "        \"2's (num)\": num_2, \"2's (%)\": perc_2,\n",
    "        \"1's (num)\": num_1, \"1's (%)\": perc_1,\n",
    "        \"Overall Average %\": np.round((perc_3 * 3 + perc_2 * 2 + perc_1 * 1) / 3,2)\n",
    "    }\n",
    "\n",
    "\n",
    "# Step 4: Convert to DataFrame for better display\n",
    "indirect_attainment_df = pd.DataFrame(results).T\n",
    "\n",
    "print(indirect_attainment_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c24a4b7",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'final_CO_attainment_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 32\u001b[39m\n\u001b[32m      6\u001b[39m multi_columns = pd.MultiIndex.from_tuples([\n\u001b[32m      7\u001b[39m \n\u001b[32m      8\u001b[39m     \u001b[38;5;66;03m# ------- DIRECT ASSESSMENT (90%) -------\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     28\u001b[39m     (\u001b[33m\"\u001b[39m\u001b[33mResult\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mCO Attainment\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     29\u001b[39m ])\n\u001b[32m     31\u001b[39m \u001b[38;5;66;03m# 2) CREATE EMPTY REPORT WITH MULTI-HEADERS\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m32\u001b[39m final_report_df = pd.DataFrame(index=\u001b[43mfinal_CO_attainment_df\u001b[49m.index, columns=multi_columns)\n\u001b[32m     34\u001b[39m \u001b[38;5;66;03m# 3) MAP VALUES INTO NBA FORMAT\u001b[39;00m\n\u001b[32m     35\u001b[39m \n\u001b[32m     36\u001b[39m \u001b[38;5;66;03m# --- Internal Assessment Tools ---\u001b[39;00m\n\u001b[32m     37\u001b[39m final_report_df[(\u001b[33m\"\u001b[39m\u001b[33mDirect Assessment (90\u001b[39m\u001b[33m%\u001b[39m\u001b[33m)\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mInternal Assessment\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mTool 1\u001b[39m\u001b[33m\"\u001b[39m)] = CO_attain_df[\u001b[33m\"\u001b[39m\u001b[33mTool 1\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[31mNameError\u001b[39m: name 'final_CO_attainment_df' is not defined"
     ]
    }
   ],
   "source": [
    "# ================================\n",
    "# NBA STYLE MULTI-ROW REPORT\n",
    "# ================================\n",
    "\n",
    "# 1) DEFINE MULTI-LEVEL HEADER\n",
    "multi_columns = pd.MultiIndex.from_tuples([\n",
    "\n",
    "    # ------- DIRECT ASSESSMENT (90%) -------\n",
    "    (\"Direct Assessment (90%)\", \"Internal Assessment\", \"Tool 1\"),\n",
    "    (\"Direct Assessment (90%)\", \"Internal Assessment\", \"Tool 2\"),\n",
    "    (\"Direct Assessment (90%)\", \"Internal Assessment\", \"Tool 3\"),\n",
    "\n",
    "    (\"Direct Assessment (90%)\", \"Internal Attainment %\", \"\"),\n",
    "    (\"Direct Assessment (90%)\", \"Internal Attainment Level\", \"\"),\n",
    "\n",
    "    (\"Direct Assessment (90%)\", \"End Sem Exam Attainment %\", \"\"),\n",
    "    (\"Direct Assessment (90%)\", \"End Sem Exam Attainment Level\", \"\"),\n",
    "\n",
    "    (\"Direct Assessment (90%)\", \"Direct Attainment Level\", \"\"),\n",
    "\n",
    "    # ------- INDIRECT ASSESSMENT (10%) -------\n",
    "    (\"Indirect Assessment (10%)\", \"Course Exit Survey\", \"\"),\n",
    "    (\"Indirect Assessment (10%)\", \"Indirect Attainment Level\", \"\"),\n",
    "\n",
    "    # ------- FINAL / TARGET / RESULT -------\n",
    "    (\"Final\", \"Final Attainment Level (Direct 90% + Indirect 10%)\", \"\"),\n",
    "    (\"Target\", \"CO Attainment Target\", \"\"),\n",
    "    (\"Result\", \"CO Attainment\", \"\")\n",
    "])\n",
    "\n",
    "# 2) CREATE EMPTY REPORT WITH MULTI-HEADERS\n",
    "final_report_df = pd.DataFrame(index=final_CO_attainment_df.index, columns=multi_columns)\n",
    "\n",
    "# 3) MAP VALUES INTO NBA FORMAT\n",
    "\n",
    "# --- Internal Assessment Tools ---\n",
    "final_report_df[(\"Direct Assessment (90%)\", \"Internal Assessment\", \"Tool 1\")] = CO_attain_df[\"Tool 1\"]\n",
    "final_report_df[(\"Direct Assessment (90%)\", \"Internal Assessment\", \"Tool 2\")] = CO_attain_df[\"Tool 2\"]\n",
    "final_report_df[(\"Direct Assessment (90%)\", \"Internal Assessment\", \"Tool 3\")] = CO_attain_df[\"Tool 3\"]\n",
    "\n",
    "# --- Internal Attainment ---\n",
    "final_report_df[(\"Direct Assessment (90%)\", \"Internal Attainment %\", \"\")] = final_CO_attainment_df[\"Internal Attainment %\"]\n",
    "final_report_df[(\"Direct Assessment (90%)\", \"Internal Attainment Level\", \"\")] = final_CO_attainment_df[\"Internal Attainment Level\"]\n",
    "\n",
    "# --- End Sem Attainment ---\n",
    "final_report_df[(\"Direct Assessment (90%)\", \"End Sem Exam Attainment %\", \"\")] = final_CO_attainment_df[\"End Sem Exam Attainment %\"]\n",
    "final_report_df[(\"Direct Assessment (90%)\", \"End Sem Exam Attainment Level\", \"\")] = final_CO_attainment_df[\"End Sem Exam Attainment Level\"]\n",
    "\n",
    "# --- Direct Level ---\n",
    "final_report_df[(\"Direct Assessment (90%)\", \"Direct Attainment Level\", \"\")] = final_CO_attainment_df[\"Direct Attainment Level\"]\n",
    "\n",
    "# --- Indirect ---\n",
    "final_report_df[(\"Indirect Assessment (10%)\", \"Course Exit Survey\", \"\")] = final_CO_attainment_df[\"Course Exit Survey\"]\n",
    "final_report_df[(\"Indirect Assessment (10%)\", \"Indirect Attainment Level\", \"\")] = final_CO_attainment_df[\"Indirect Attainment Level\"]\n",
    "\n",
    "# --- Final / Target / Result ---\n",
    "final_report_df[(\"Final\", \"Final Attainment Level (Direct 90% + Indirect 10%)\", \"\")] = final_CO_attainment_df[\"Final Attainment Level\"]\n",
    "final_report_df[(\"Target\", \"CO Attainment Target\", \"\")] = TARGET_ATTAINMENT_LEVEL\n",
    "final_report_df[(\"Result\", \"CO Attainment\", \"\")] = final_CO_attainment_df[\"CO Attainment\"]\n",
    "\n",
    "# 4) ROUND\n",
    "final_report_df = final_report_df.round(2)\n",
    "\n",
    "# 5) SHOW IN NOTEBOOK\n",
    "final_report_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10c12631",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36597e81",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bfa1ef8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f8806b7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xie_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
